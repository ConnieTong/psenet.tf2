#!/usr/bin/python3
# __*__ coding: utf-8 __*__

'''
@Author: SimonWang00
@Os：Windows 10 x64
@Contact: simon_wang00@163.com
@Software: PY PyCharm
@File: settings.py
@Time: 2020/12/15 15:15
'''

# Copyright 2020 The SimonWang00. All Rights Reserved.
#
# @Desc:
# 1).define down_top_layer;
# 2).define top_down_layer;
# 3).define Lateral connections;
# ==============================================================================
# LINT.IfChange

"""using tf2.0 build feature pyramid package"""

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, UpSampling2D, BatchNormalization, Activation
from resnet_net import build_resnet
from typing import List,Tuple

from settings import BACKBONE, TRAIN_BN, TOP_DOWN_PYRAMID_SIZE


def down_top_layer(input_image) -> Tuple:
    '''
    # Top-down Layers Lateral connections

    For RESNET feed-forward calculation, it is a bottom-up path.
    The author uses the feature activation output of the last residual structure in each stage.
    The outputs of these residual modules are expressed as {C2, C3, C4, C5},
    corresponding to the outputs of conv2, conv3, conv4 and conv5,
    and note that they have {4, 8, 16, 32} pixel steps relative to the input image.
    Parameters
    ----------
    input_image :

    Returns: _, C2, C3, C4, C5
    -------

    '''
    _, C2, C3, C4, C5 = build_resnet(input_image, BACKBONE,stage5=True, train_bn=TRAIN_BN)
    return _, C2, C3, C4, C5


def top_down_and_merge_layer(C2, C3, C4, C5) -> List:
    '''
    # Top-down Layers  and Lateral connections
    The high-level features are sampled twice (the nearest up sampling method),
    and then they are combined with the corresponding features of the previous layer
    (the former layer can only be used after 1 * 1 convolution kernel,
    so as to change channels, which should be the same as the channels of the latter layer).
    The combination method is to add the pixels.
    Repeat the iterative process until the most refined feature map is generated.
    At the beginning of the iteration, the author adds a 1 * 1 convolution kernel to the C5 layer to generate the coarsest feature map.
    Finally, the author uses the 3 * 3 convolution kernel to process the fused feature map
    (in order to eliminate the aliasing effect of the upper sampling) to generate the final required feature map.
    The fusion feature layer of {C2, C3, C4, C5} layer is {P2, P3, P4, P5}, and the corresponding layer space size is the same.

    Parameters after down top layer
    ----------
    C2 :
    C3 :
    C4 :
    C5 :

    Returns mrcnn_feature_maps
    -------

    '''

    P5 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')(C5)

    p5_ups2D = UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(P5) # upper sample
    # '''1x1的卷积我认为有三个作用：使bottom-up对应层降维至256；缓冲作用，防止梯度直接影响bottom-up主干网络，更稳定；组合特征。'''
    C4 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), padding="SAME", name='fpn_c4p4')(C4) # fit size
    P4 = tf.keras.layers.Add(name="fpn_p4add")([p5_ups2D,C4])   # merge P5 and C4

    p4_ups2D = UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(P4)
    C3 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), padding="SAME", name='fpn_c3p3')(C3)
    P3 = tf.keras.layers.Add(name="fpn_p3add")([p4_ups2D,C3])

    p3_ups2D = UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(P3)
    C2 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), padding="SAME", name='fpn_c2p2')(C2)
    P2 = tf.keras.layers.Add(name="fpn_p2add")([p3_ups2D,C2])

    # Attach 3x3 conv to all P layers to get the final feature maps.
    P2 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p2")(P2)
    P3 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p3")(P3)
    P4 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p4")(P4)
    P5 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", name="fpn_p5")(P5)

    # P6 is used for the 5th anchor scale in RPN. Generated by
    # subsampling from P5 with stride of 2.
    # P6 = MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)

    # Note that P6 is used in RPN, but not in the classifier heads.
    # rpn_feature_maps = [P2, P3, P4, P5, P6]

    mrcnn_feature_maps = [P2, P3, P4, P5]

    return mrcnn_feature_maps

def unpooling(input_data, factor: int) -> tf.Tensor:
    '''
    #TODO:bilinear or nearest_neighbor?

    Parameters
    ----------
    input_data :

    Returns
    -------

    '''
    if factor == 0:
        return input_data
    return UpSampling2D((2**factor,2**factor))(input_data)

def build_feature_pyramid(input_images) -> tf.Tensor:
    '''
    build P2, P3, P4, P5

    we fuse the four feature maps to get feature map F with 1024 channels via the function
    C(·) as: F = C(P2, P3, P4, P5) = P2 || Up×2(P3) || Up×4(P4) || Up×8 (P5), where “k” refers to the concatenation and Up×2
    (·), Up×4 (·), Up×8 (·) refer to 2, 4, 8 times upsampling

    References:https://github.com/liuheng92/tensorflow_PSENet/

    Parameters
    ----------
    rpn_feature_maps :

    Returns
    -------

    '''

    _, C2, C3, C4, C5 = down_top_layer(input_images)
    rpn_feature_maps = top_down_and_merge_layer(C2, C3, C4, C5)

    '''rpn_feature_maps: (None, 320, 320, 256) (None, 160, 160, 256)  (None, 80, 80, 256)  (None, 40, 40, 256)'''
    rpn_feature_maps = [unpooling(feature_map, i) for i,feature_map in enumerate(rpn_feature_maps)]
    F = tf.concat(rpn_feature_maps, axis=-1)      #(None, 40, 40, 1024)
    # F = tf.keras.layers.Concatenate(axis=-1)(rpn_feature_maps)
    # print(F.shape)
    # reduce to 256 channels    (None, 40, 40, 256)
    F = Conv2D(TOP_DOWN_PYRAMID_SIZE,(3, 3), padding="SAME",name="build_feature_pyramid")(F)
    # print(F.shape)
    F = BatchNormalization()(F)
    F = Activation("relu")(F)

    return F